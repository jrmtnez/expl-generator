# Expl Generator
This repository includes the source code and dataset described in our research article Generating Explanations for Non-explanatory Fake News Detection Systems.

## Installation

It is recommended that you use a separate Python 3.11 virtual environment for this application.

The required packages can be installed as follows:

```bash
$ pip install -r requirements.txt
```

## Application Description

The primary folders of the application are described below.

- [data](data/) contains the dataset (news_items.json) with the news items to be evaluated.

- [llm_mgmt](llm_mgmt/) contains Python scripts to handle different LLMs including models managed with the Ollama framework and models downloaded from Hugging Face.

- [prompt_library](prompt_library/)  contains the definition of the different prompts used to generate explanations, evaluate explanations, and other intermediate tasks.

- [rag_mgmt](rag_mgmt/) contains the scripts responsible for handling search engine queries, with functionality encompassing website reliability estimation.

### Generating Explanations

Running the [pipeline_loop.py](pipeline/pipeline_loop.py) script will generate the explanations for the two selected models (DeepSeek R1 8B and Gemma 3 12B IT) in the [results](results/) folder.

Running the [openai_loop.py](pipeline/openai_loop.py) script will generate the reference explanations using the GPT 4.1 model. Access keys are required for it to work.

### Evaluating the Explanations

The [evaluation](evaluation/) folder contains scripts for evaluating explanations generated by small LLMs DeepSeek R1 8B and Gemma 3 12B IT. Specifically, [s01_extract_explanations.py](evaluation/s01_extract_explanations.py) generates the base JSON files, [s02_evaluate_intermediate_explanations.py](evaluation/s02_evaluate_intermediate_explanations.py) evaluates the intermediate data and explanations, and [s03_evaluate_final_explanations.py](evaluation/s03_evaluate_final_explanations.py) evaluates the final explanations, including those generated by the GPT-4.1 reference model. These scripts must be executed in this order.

Models DeepSeek R1 32B and Gemma 3 27B IT are used for the evaluation.

## License and Disclaimer
Please see the LICENSE file for details. Downloading data indicates your acceptance of our disclaimer.

## Citation
```bibtex
@article{martinez-rico_generating_2025,
	title = {Generating {Explanations} for {Non}-explanatory {Fake} {News} {Detection} {Systems}},
	language = {en},
	author = {Martinez-Rico, Juan R and Martinez-Romo, Juan and Araujo, Lourdes},
	year = {2025}
}
```